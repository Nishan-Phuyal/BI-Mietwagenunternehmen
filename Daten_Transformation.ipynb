{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import ast\n",
    "import numpy as np \n",
    "import string\n",
    "import time\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.read_csv(\"driver_activity.csv\") # Import Driver Activity\n",
    "dq = pd.read_csv(\"driver_quality.csv\") # Import drivers_quality \n",
    "dp = pd.read_csv(\"payments_order.csv\") # Import payment order\n",
    "tl = pd.read_csv(\"trip_location.csv\") # Import trip Location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting coordinates of pick up and drop-off location , delay the funtion by one second to avoid trace error.. \n",
    "\n",
    "def get_lan_lng_geopy(adress):\n",
    "    geolocator = Nominatim(user_agent= \"Germany\")\n",
    "    time.sleep(1)\n",
    "    location = geolocator.geocode(adress)\n",
    "    if location: \n",
    "        return location.latitude, location.longitude\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the function for extracting geo location. \n",
    "abhol_geo_location = []\n",
    "ziel_geo_location = []\n",
    "for i ,j in zip(tl[\"Abholadresse\"], tl[\"Zieladresse\"]):\n",
    "     abhol_geo_location.append(get_lan_lng_geopy(i))\n",
    "     ziel_geo_location.append(get_lan_lng_geopy(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the geo location stored in list into the dataframe \n",
    "tl[\"Abhol_geo\"] = abhol_geo_location \n",
    "tl[\"Ziel_geo\"] = ziel_geo_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to transfrom the online time from DD:HH:MM to total hours online\n",
    "def in_to_hours(x):\n",
    "    a = (x.split(\":\"))\n",
    "    return round(int(a[0])*24 + int(a[1]) + (int(a[2])/60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply funtion \n",
    "da[\"Online\"] = da[\"Zeit online (Tage: Stunden: Minuten)\"].apply(in_to_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defina a function to reverse the type of an entry into its original format from a String, althouh need to repeat again once saved as csv\n",
    "def redo_type(x):\n",
    "    #check if x is NAN using pandas \n",
    "    if pd.notna(x):\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except(ValueError, SyntaxError):\n",
    "            return x\n",
    "    else:\n",
    "        return np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing into the geo data, which is essentially a Tuple datatype but recorded as string\n",
    "tl['Abhol_geo'] = tl['Abhol_geo'].apply(redo_type)\n",
    "tl[\"Ziel_geo\"] = tl[\"Ziel_geo\"].apply(redo_type)\n",
    "tl[\"Date\"]= pd.to_datetime(tl[\"Zeitpunkt der Fahrtbestellung\"]).dt.strftime('%d.%b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the column \n",
    "dq.columns.values[8] = \"Fahrer_Bewertung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the column\n",
    "dp.columns.values[10] = \"Fahrt_Umsatz\"\n",
    "dp.columns.values[26] = \"Aktion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the tables based on entity relation.\n",
    "df = pd.merge(tl,dq, on=\"Fahrer-UUID\", how=\"left\")\n",
    "df = pd.merge(df,da, on=\"Fahrer-UUID\", how=\"left\")\n",
    "df = pd.merge(df,da, on=\"Fahrer-UUID\", how=\"left\")\n",
    "df = pd.merge(df,dp[[\"Fahrt_Umsatz\",\"Aktion\",\"Fahrt-UUID\"]], on=\"Fahrt-UUID\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only relevant columns..\n",
    "data = df[[\"Vorname des Fahrers_x\",\"Nachname des Fahrers_x\",\"Abholadresse\", \"Zieladresse\", \n",
    "    \"Fahrtdistanz\", \"Abhol_geo\", \"Ziel_geo\", \"Abgeschlossene Fahrten_x\", \"Annahmerate\",\n",
    "    \"Fahrer_Bewertung\",'Online', 'Fahrt_Umsatz', 'Aktion', \"Date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns \n",
    "data.columns.values[0] = \"First_Name\"\n",
    "data.columns.values[1] = \"last_Name\"\n",
    "data.columns.values[7] = \"Abgeschlossene_Fahrten\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fullname, to avoid duplicates \n",
    "data[\"Drivers_Name\"] = data[\"First_Name\"] + \" \" + data[\"last_Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introducing pseudo Names for each Driver.. \n",
    "pair = {}\n",
    "for i,j in zip(data[\"Drivers_Name\"].unique(), [i.upper() for i in string.ascii_letters]):\n",
    "    pair[i] = j + \"xter\" + \" \" + j +\"ustermann\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to dataframe \n",
    "paired = pd.DataFrame(list(pair.items()), columns=['Drivers_Name', 'Pseudo_Drivers_Name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging into the data, something like vlook in excel \n",
    "data = pd.merge(data, paired, on = \"Drivers_Name\", how = \"left\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing first name and last name of Drivers \n",
    "data = data.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the full name of Drivers \n",
    "data.drop(\"Drivers_Name\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for futher use \n",
    "# data.to_csv(\"data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
